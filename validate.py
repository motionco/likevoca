#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Complete Data Validation - ì™„ì „í•œ ë°ì´í„° ê²€ì¦
ì¤‘ë³µ ê²€ì¦ + ë¬´ê²°ì„± ê²€ì¦ + í•„ë“œ ì™„ì„±ë„ ê²€ì¦ + í¬ë§· ê²€ì¦
"""

import csv
import os
from pathlib import Path

# ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent
DATA_DIR = PROJECT_ROOT / "data"

def ensure_directories():
    """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
    DATA_DIR.mkdir(exist_ok=True)

def validate_duplicates():
    """_add.csv íŒŒì¼ë“¤ê³¼ ê¸°ì¡´ _list.csv íŒŒì¼ë“¤ ê°„ êµì°¨ ì¤‘ë³µ ê²€ì¦"""
    print("ğŸ¯ ì¤‘ë³µ ê²€ì¦ (_add.csv â†” _list.csv êµì°¨ ê²€ì¦)")
    print("="*50)
    
    # 1. ê¸°ì¡´ _list.csv ë°ì´í„° ìˆ˜ì§‘
    existing_concept_ids = set()
    existing_word_meanings = set()
    
    list_files = ["concepts_template_list.csv", "examples_template_list.csv", "grammar_template_list.csv"]
    for file_name in list_files:
        file_path = DATA_DIR / file_name
        if file_path.exists():
            try:
                with open(file_path, "r", encoding="utf-8-sig") as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        concept_id = row.get('concept_id', '')
                        if concept_id:
                            existing_concept_ids.add(concept_id)
                            
                            # concepts íŒŒì¼ì—ì„œ ë‹¨ì–´+ì˜ë¯¸ ì¡°í•© ìˆ˜ì§‘
                            if "concepts_template" in file_name:
                                english_word = row.get('english_word', '')
                                korean_word = row.get('korean_word', '')
                                if english_word and korean_word:
                                    parts = concept_id.split('_')
                                    meaning = parts[-1] if len(parts) >= 3 else 'unknown'
                                    en_combination = f"{english_word}_{meaning}"
                                    ko_combination = f"{korean_word}_{meaning}"
                                    existing_word_meanings.add(en_combination)
                                    existing_word_meanings.add(ko_combination)
            except Exception as e:
                print(f"âš ï¸ {file_name} ì½ê¸° ì˜¤ë¥˜: {e}")
    
    print(f"ğŸ“Š ê¸°ì¡´ ë°ì´í„°: {len(existing_concept_ids)}ê°œ concept_id, {len(existing_word_meanings)}ê°œ ë‹¨ì–´+ì˜ë¯¸ ì¡°í•©")
    
    # 2. _add.csv íŒŒì¼ë“¤ ê²€ì¦
    files_to_check = [
        "concepts_template_add.csv",
        "examples_template_add.csv", 
        "grammar_template_add.csv"
    ]
    
    all_clean = True
    
    for file_name in files_to_check:
        file_path = DATA_DIR / file_name
        if not file_path.exists():
            print(f"âšª {file_name}: íŒŒì¼ ì—†ìŒ")
            continue
            
        try:
            with open(file_path, "r", encoding="utf-8-sig") as f:
                reader = csv.DictReader(f)
                rows = list(reader)
            
            if not rows:
                print(f"âšª {file_name}: ë°ì´í„° ì—†ìŒ")
                continue
            
            # 1. concept_id ì¤‘ë³µ ê²€ì‚¬ (ë‚´ë¶€ + êµì°¨)
            concept_ids = [row.get('concept_id', '') for row in rows if row.get('concept_id')]
            concept_id_duplicates = []
            cross_concept_id_duplicates = []
            seen_concept_ids = set()
            
            for concept_id in concept_ids:
                # ë‚´ë¶€ ì¤‘ë³µ ê²€ì‚¬
                if concept_id in seen_concept_ids:
                    concept_id_duplicates.append(concept_id)
                else:
                    seen_concept_ids.add(concept_id)
                
                # ê¸°ì¡´ _list.csvì™€ êµì°¨ ì¤‘ë³µ ê²€ì‚¬
                if concept_id in existing_concept_ids:
                    cross_concept_id_duplicates.append(concept_id)
            
            # 2. ë‹¨ì–´+ì˜ë¯¸ ì¡°í•© ì¤‘ë³µ ê²€ì‚¬ (concepts íŒŒì¼ë§Œ)
            word_meaning_duplicates = []
            cross_word_meaning_duplicates = []
            if "concepts_template" in file_name:
                word_meaning_combinations = []
                for row in rows:
                    concept_id = row.get('concept_id', '')
                    english_word = row.get('english_word', '')
                    korean_word = row.get('korean_word', '')
                    
                    if concept_id and english_word and korean_word:
                        # concept_idì—ì„œ ì˜ë¯¸ ì¶”ì¶œ
                        parts = concept_id.split('_')
                        meaning = parts[-1] if len(parts) >= 3 else 'unknown'
                        
                        # ì˜ì–´ ë‹¨ì–´+ì˜ë¯¸, í•œêµ­ì–´ ë‹¨ì–´+ì˜ë¯¸ ì¡°í•©
                        en_combination = f"{english_word}_{meaning}"
                        ko_combination = f"{korean_word}_{meaning}"
                        word_meaning_combinations.append((en_combination, ko_combination, concept_id))
                        
                        # ê¸°ì¡´ _list.csvì™€ êµì°¨ ì¤‘ë³µ ê²€ì‚¬
                        if en_combination in existing_word_meanings or ko_combination in existing_word_meanings:
                            cross_word_meaning_duplicates.append((concept_id, en_combination, ko_combination))
                
                # ì¤‘ë³µ ê²€ì‚¬
                seen_combinations = set()
                for en_combo, ko_combo, concept_id in word_meaning_combinations:
                    if en_combo in seen_combinations or ko_combo in seen_combinations:
                        word_meaning_duplicates.append(f"{concept_id} ({en_combo})")
                    else:
                        seen_combinations.add(en_combo)
                        seen_combinations.add(ko_combo)
            
            # ê²°ê³¼ ì¶œë ¥
            has_duplicates = concept_id_duplicates or word_meaning_duplicates or cross_concept_id_duplicates or cross_word_meaning_duplicates
            
            if has_duplicates:
                if concept_id_duplicates:
                    print(f"âŒ {file_name}: íŒŒì¼ ë‚´ concept_id ì¤‘ë³µ {len(concept_id_duplicates)}ê°œ")
                    for dup in concept_id_duplicates[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                        print(f"   ğŸ”„ {dup}")
                
                if cross_concept_id_duplicates:
                    print(f"âŒ {file_name}: ê¸°ì¡´ ë°ì´í„°ì™€ concept_id ì¤‘ë³µ {len(cross_concept_id_duplicates)}ê°œ")
                    for dup in cross_concept_id_duplicates[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                        print(f"   âš ï¸ {dup}")
                
                if word_meaning_duplicates:
                    print(f"âŒ {file_name}: íŒŒì¼ ë‚´ ë‹¨ì–´+ì˜ë¯¸ ì¤‘ë³µ {len(word_meaning_duplicates)}ê°œ")
                    for dup in word_meaning_duplicates[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                        print(f"   ğŸ”„ {dup}")
                
                if cross_word_meaning_duplicates:
                    print(f"âŒ {file_name}: ê¸°ì¡´ ë°ì´í„°ì™€ ë‹¨ì–´+ì˜ë¯¸ ì¤‘ë³µ {len(cross_word_meaning_duplicates)}ê°œ")
                    for concept_id, en_combo, ko_combo in cross_word_meaning_duplicates[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                        print(f"   âš ï¸ {concept_id} ({en_combo} or {ko_combo})")
                
                all_clean = False
            else:
                print(f"âœ… {file_name}: ì¤‘ë³µ ì—†ìŒ ({len(rows)}ê°œ ë°ì´í„°)")
        
        except Exception as e:
            print(f"âŒ {file_name}: ê²€ì¦ ì‹¤íŒ¨ ({e})")
            all_clean = False
    
    print("\nğŸ“Š ê²€ì¦ ê²°ê³¼:")
    if all_clean:
        print("âœ… ëª¨ë“  íŒŒì¼ì—ì„œ ì¤‘ë³µ ì—†ìŒ")
    else:
        print("âŒ ì¤‘ë³µ ë°œê²¬ - ìˆ˜ì • í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”")
    
    return all_clean


def validate_field_completeness():
    """í•„ë“œ ì™„ì„±ë„ ê²€ì¦"""
    print("\nğŸ” í•„ë“œ ì™„ì„±ë„ ê²€ì¦")
    print("="*50)
    
    files_to_check = [
        ("concepts_template_add.csv", 58),
        ("examples_template_add.csv", 16), 
        ("grammar_template_add.csv", 31),
        ("concepts_template_list.csv", 58),
        ("examples_template_list.csv", 16),
        ("grammar_template_list.csv", 31)
    ]
    
    for file_name, expected_fields in files_to_check:
        file_path = DATA_DIR / file_name
        if not file_path.exists():
            print(f"âšª {file_name}: íŒŒì¼ ì—†ìŒ")
            continue
            
        try:
            with open(file_path, "r", encoding="utf-8-sig") as f:
                reader = csv.DictReader(f)
                fieldnames = reader.fieldnames
                rows = list(reader)
            
            if not fieldnames:
                print(f"âŒ {file_name}: í—¤ë” ì—†ìŒ")
                continue
                
            # í•„ë“œ ìˆ˜ ê²€ì¦ (ì •í™•í•œ ê³„ì‚°)
            actual_fields = len(fieldnames)
            print(f"ğŸ” {file_name}: {actual_fields}ê°œ í•„ë“œ (ì˜ˆìƒ: {expected_fields}ê°œ)")
            
            if actual_fields != expected_fields:
                print(f"âŒ {file_name}: í•„ë“œ ìˆ˜ ë¶ˆì¼ì¹˜ ({actual_fields}/{expected_fields})")
                # ì¶”ê°€ëœ í•„ë“œê°€ ìˆë‹¤ë©´ ì²˜ìŒ ëª‡ ê°œ í‘œì‹œ
                if actual_fields > expected_fields:
                    extra_count = actual_fields - expected_fields
                    print(f"   âš ï¸ {extra_count}ê°œ í•„ë“œ ì¶”ê°€ë¨")
            else:
                print(f"âœ… {file_name}: í•„ë“œ ìˆ˜ ì •ìƒ ({actual_fields}ê°œ)")
            
            # ë¹ˆ í•„ë“œ ê²€ì¦
            if rows:
                empty_field_count = 0
                total_field_count = len(rows) * len(fieldnames)
                
                for row in rows:
                    for field_name, value in row.items():
                        if not value or value.strip() == "":
                            empty_field_count += 1
                
                completion_rate = ((total_field_count - empty_field_count) / total_field_count) * 100
                
                if completion_rate < 50:
                    print(f"âŒ {file_name}: ì™„ì„±ë„ {completion_rate:.1f}% (ë„ˆë¬´ ë‚®ìŒ)")
                elif completion_rate < 80:
                    print(f"âš ï¸ {file_name}: ì™„ì„±ë„ {completion_rate:.1f}% (ê°œì„  í•„ìš”)")
                else:
                    print(f"âœ… {file_name}: ì™„ì„±ë„ {completion_rate:.1f}% (ì–‘í˜¸)")
                    
        except Exception as e:
            print(f"âŒ {file_name}: ê²€ì¦ ì‹¤íŒ¨ ({e})")

def validate_data_integrity():
    """ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦"""
    print("\nğŸ” ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦")
    print("="*50)
    
    # concept_id ì¼ê´€ì„± ê²€ì¦
    add_concepts = set()
    list_concepts = set()
    
    # _add.csv íŒŒì¼ë“¤ì˜ concept_id ìˆ˜ì§‘
    for file_name in ["concepts_template_add.csv", "examples_template_add.csv", "grammar_template_add.csv"]:
        file_path = DATA_DIR / file_name
        if file_path.exists():
            try:
                with open(file_path, "r", encoding="utf-8-sig") as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        if row.get('concept_id'):
                            add_concepts.add(row['concept_id'])
            except Exception as e:
                print(f"âš ï¸ {file_name} ì½ê¸° ì‹¤íŒ¨: {e}")
    
    # _list.csv íŒŒì¼ë“¤ì˜ concept_id ìˆ˜ì§‘
    for file_name in ["concepts_template_list.csv", "examples_template_list.csv", "grammar_template_list.csv"]:
        file_path = DATA_DIR / file_name
        if file_path.exists():
            try:
                with open(file_path, "r", encoding="utf-8-sig") as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        if row.get('concept_id'):
                            list_concepts.add(row['concept_id'])
            except Exception as e:
                print(f"âš ï¸ {file_name} ì½ê¸° ì‹¤íŒ¨: {e}")
    
    # concept_id ì¼ê´€ì„± ê²€ì¦
    if add_concepts:
        print(f"ğŸ“Š _add.csv íŒŒì¼ë“¤: {len(add_concepts)}ê°œ concept_id")
        
        # ê° _add.csv íŒŒì¼ ê°„ concept_id ì¼ì¹˜ í™•ì¸
        files_concepts = {}
        for file_name in ["concepts_template_add.csv", "examples_template_add.csv", "grammar_template_add.csv"]:
            file_path = DATA_DIR / file_name
            if file_path.exists():
                try:
                    with open(file_path, "r", encoding="utf-8-sig") as f:
                        reader = csv.DictReader(f)
                        file_concepts = {row['concept_id'] for row in reader if row.get('concept_id')}
                        files_concepts[file_name] = file_concepts
                except:
                    continue
        
        # ì¼ê´€ì„± ê²€ì¦
        if len(files_concepts) > 1:
            all_concepts = list(files_concepts.values())
            if all(concepts == all_concepts[0] for concepts in all_concepts):
                print("âœ… _add.csv íŒŒì¼ë“¤ ê°„ concept_id ì¼ì¹˜")
            else:
                print("âŒ _add.csv íŒŒì¼ë“¤ ê°„ concept_id ë¶ˆì¼ì¹˜")
                for file_name, concepts in files_concepts.items():
                    print(f"   {file_name}: {concepts}")
    
    if list_concepts:
        print(f"ğŸ“Š _list.csv íŒŒì¼ë“¤: {len(list_concepts)}ê°œ concept_id")

def validate_format():
    """í¬ë§· ê²€ì¦"""
    print("\nğŸ“ í¬ë§· ê²€ì¦")
    print("="*50)
    
    files_to_check = [
        "concepts_template_add.csv",
        "examples_template_add.csv", 
        "grammar_template_add.csv",
        "concepts_template_list.csv",
        "examples_template_list.csv",
        "grammar_template_list.csv"
    ]
    
    for file_name in files_to_check:
        file_path = DATA_DIR / file_name
        if not file_path.exists():
            print(f"âšª {file_name}: íŒŒì¼ ì—†ìŒ")
            continue
            
        try:
            with open(file_path, "r", encoding="utf-8-sig") as f:
                reader = csv.DictReader(f)
                rows = list(reader)
            
            if not rows:
                print(f"âšª {file_name}: ë°ì´í„° ì—†ìŒ")
                continue
            
            # concept_id í¬ë§· ê²€ì¦
            invalid_concept_ids = []
            for row in rows:
                concept_id = row.get('concept_id', '')
                if concept_id:
                    # {domain}_{word}_{meaning} í˜•ì‹ ê²€ì¦ (ìµœì†Œ 3ê°œ ë¶€ë¶„)
                    parts = concept_id.split('_')
                    if len(parts) < 3:
                        invalid_concept_ids.append(f"{concept_id} (ë¶€ë¶„ ìˆ˜: {len(parts)})")
                    else:
                        # ë„ë©”ì¸ ê²€ì¦ (ì„ íƒì‚¬í•­ - ì•Œë ¤ì§„ ë„ë©”ì¸ ëª©ë¡ê³¼ ë¹„êµ)
                        known_domains = ["daily", "food", "travel", "health", "nature", "shopping", 
                                       "education", "technology", "business", "culture", "sports", "entertainment"]
                        domain = parts[0]
                        if domain not in known_domains:
                            invalid_concept_ids.append(f"{concept_id} (ì•Œ ìˆ˜ ì—†ëŠ” ë„ë©”ì¸: {domain})")
            
            if invalid_concept_ids:
                print(f"âŒ {file_name}: ì˜ëª»ëœ concept_id í˜•ì‹ {len(invalid_concept_ids)}ê°œ")
                for invalid_id in invalid_concept_ids[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                    print(f"   âš ï¸ {invalid_id}")
            else:
                print(f"âœ… {file_name}: concept_id í˜•ì‹ ì •ìƒ")
                
        except Exception as e:
            print(f"âŒ {file_name}: í¬ë§· ê²€ì¦ ì‹¤íŒ¨ ({e})")

if __name__ == "__main__":
    ensure_directories()
    
    print("ğŸ” Complete Data Validation")
    print("="*50)
    
    # 1. ì¤‘ë³µ ê²€ì¦
    validate_duplicates()
    
    # 2. í•„ë“œ ì™„ì„±ë„ ê²€ì¦  
    validate_field_completeness()
    
    # 3. ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
    validate_data_integrity()
    
    # 4. í¬ë§· ê²€ì¦
    validate_format()
    
    print("\nğŸ‰ ê²€ì¦ ì™„ë£Œ!")
    print("ğŸ’¡ ë¬¸ì œê°€ ë°œê²¬ëœ ê²½ìš° ìœ„ì˜ ë©”ì‹œì§€ë¥¼ ì°¸ê³ í•˜ì—¬ ìˆ˜ì •í•˜ì„¸ìš”.")
