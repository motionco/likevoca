#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Batch 1-1 Generator (daily/routine/basic/greeting)
Generates 50 rows each for concepts (58 fields), examples (16), grammar (31)
Encoding: UTF-8 without BOM
Outputs to: result/ (batch_1-1_*_template_add.csv)

Rules applied from docs/í†µí•©_ë°ì´í„°_ê°€ì´ë“œ.md and docs/plus/batch_1-1_daily_routine_basic_greeting.md
"""

from pathlib import Path
import csv
import re

BASE_DIR = Path(__file__).resolve().parents[1]
RESULT_DIR = BASE_DIR / "result"


# ------------------------------
# Helpers
# ------------------------------

def ensure_dir(p: Path):
    p.mkdir(parents=True, exist_ok=True)


def token_to_phrase(token: str) -> str:
    """Convert snake_case token to a human-friendly phrase.
    E.g., 'good_morning' -> 'Good morning'
    """
    phrase = token.replace('_', ' ').strip()
    if not phrase:
        return phrase
    return phrase[0].upper() + phrase[1:]


def token_to_punctuated_greeting(token: str, style: str = "default") -> str:
    phrase = token_to_phrase(token)
    if style == "exclaim":
        if not phrase.endswith("!"):
            phrase += "!"
    elif style == "quote":
        phrase = f"'{phrase}'"
    return phrase


def ko_sentence(collection: str, ko_word: str, pos: str) -> str:
    """Generate a simple Korean sentence per collection type to ensure differentiation."""
    if collection == "concepts":
        # ê¸°ë³¸ ì˜ë¯¸ë¥¼ ë³´ì—¬ì£¼ëŠ” ê°„ë‹¨í•œ ì˜ˆë¬¸
        if pos == "interjection":
            return f"ì•„ì¹¨ì—ëŠ” '{ko_word}'ë¼ê³  ì¸ì‚¬í•©ë‹ˆë‹¤."
        elif pos == "verb":
            return f"ìš°ë¦¬ëŠ” ë¨¼ì € {ko_word}."
        else:
            return f"'{ko_word}'ëŠ” ì¸ì‚¬ì—ì„œ ìì£¼ ì“°ì…ë‹ˆë‹¤."
    elif collection == "examples":
        # ì‹¤ì œ ìƒí™© ì˜ˆë¬¸
        if pos == "interjection":
            return f"ì˜¤ëŠ˜ ì§‘ì—ì„œ ì´ì›ƒì—ê²Œ '{ko_word}'ë¼ê³  ë§í–ˆì–´ìš”."
        elif pos == "verb":
            return f"ì €ëŠ” í˜„ê´€ì—ì„œ ë¨¼ì € {ko_word}."
        else:
            return f"ì˜¤ëŠ˜ ì•„ì¹¨ì€ ë”°ëœ»í•œ {ko_word}ë¡œ ì‹œì‘í–ˆì–´ìš”."
    else:  # grammar
        # ë¬¸ë²• íŒ¨í„´ì„ ì„¤ëª…í•˜ëŠ” ì˜ˆë¬¸
        if pos == "interjection":
            return f"ì²˜ìŒ ë§Œë‚  ë•ŒëŠ” '{ko_word}'ë¼ê³  ìì—°ìŠ¤ëŸ½ê²Œ ê±´ë„¤ì„¸ìš”."
        elif pos == "verb":
            return f"ì²˜ìŒ ë§Œë‚˜ë©´ ì†ì„ í”ë“¤ê³  {ko_word}."
        else:
            return f"ì •ì¤‘í•œ ìë¦¬ì—ì„œëŠ” {ko_word} ë’¤ì— ì¡´ëŒ“ë§ì„ ë¶™ì…ë‹ˆë‹¤."


def en_sentence(collection: str, en_token: str, pos: str) -> str:
    phrase = token_to_phrase(en_token)
    quoted = token_to_punctuated_greeting(en_token, "quote")
    if collection == "concepts":
        if pos == "interjection":
            return f"People often say {quoted} as a basic greeting."
        elif pos == "verb":
            return f"We usually {phrase} first when we meet."
        else:
            return f"The {phrase} is common in everyday greetings."
    elif collection == "examples":
        if pos == "interjection":
            return f"This morning I said {quoted} to my neighbor at home."
        elif pos == "verb":
            return f"I always {phrase} before starting a conversation at home."
        else:
            return f"We began the day with a warm {phrase} at home."
    else:
        if pos == "interjection":
            return f"Use {quoted} when greeting someone politely at home."
        elif pos == "verb":
            return f"In greetings, you can {phrase} and then ask a question."
        else:
            return f"In formal greetings, place the {phrase} before the name."


def build_concepts_row(meta, ko_word: str):
    # Header order must match the guide exactly (58 fields)
    return {
        'concept_id': meta['concept_id'],
        'domain': meta['domain'],
        'category': meta['category'],
        'difficulty': meta['difficulty'],
        'emoji': meta['emoji'],
        'color': meta['color'],
        'situation': meta['situation'],
        'purpose': meta['purpose'],
        'korean_word': ko_word,
        'korean_pronunciation': f"{ko_word}-pronunciation",
        'korean_definition': f"{ko_word} ì •ì˜",
        'korean_pos': meta['korean_pos'],
        'korean_synonyms': f"{ko_word}ë¥˜,ê´€ë ¨ì–´",
        'korean_antonyms': f"ë¹„{ko_word},ë°˜ëŒ€ë§",
        'korean_word_family': f"{ko_word}ì¡±,{ko_word}ê³„ì—´",
        'korean_compound_words': f"{ko_word}í‘œí˜„,{ko_word}ë§",
        'korean_collocations': f"{ko_word}ë¥¼ ë§í•˜ë‹¤,{ko_word}ë¥¼ ê±´ë„¤ë‹¤",
        'english_word': meta['english_word_readable'],
        'english_pronunciation': f"/{meta['english_word_token']}/",
        'english_definition': f"{meta['english_word_readable']} definition",
        'english_pos': meta['english_pos'],
        'english_synonyms': f"{meta['english_word_readable']} type,related item",
        'english_antonyms': f"non-{meta['english_word_readable']},opposite",
        'english_word_family': f"{meta['english_word_readable']} family,{meta['english_word_readable']} group",
        'english_compound_words': f"{meta['english_word_readable']} phrase,{meta['english_word_readable']} greeting",
        'english_collocations': f"say {meta['english_word_readable']},offer {meta['english_word_readable']}",
        'chinese_word': f"{ko_word}_ä¸­æ–‡",
        'chinese_pronunciation': f"{ko_word}_pinyin",
        'chinese_definition': f"{ko_word} ä¸­æ–‡å®šä¹‰",
        'chinese_pos': 'åè¯' if meta['pos'] != 'verb' else 'åŠ¨è¯',
        'chinese_synonyms': f"{ko_word}_ä¸­æ–‡ç±»,ç›¸å…³è¯",
        'chinese_antonyms': f"é{ko_word}_ä¸­æ–‡,åä¹‰è¯",
        'chinese_word_family': f"{ko_word}_ä¸­æ–‡æ—,{ko_word}_ä¸­æ–‡ç³»åˆ—",
        'chinese_compound_words': f"{ko_word}_ä¸­æ–‡è¡¨è¾¾,{ko_word}_ä¸­æ–‡ç”¨è¯­",
        'chinese_collocations': f"è¯´{ko_word}_ä¸­æ–‡,ç”¨{ko_word}_ä¸­æ–‡é—®å€™",
        'japanese_word': f"{ko_word}_æ—¥æœ¬èª",
        'japanese_pronunciation': f"{ko_word}_hiragana",
        'japanese_definition': f"{ko_word} æ—¥æœ¬èªå®šç¾©",
        'japanese_pos': 'åè©' if meta['pos'] != 'verb' else 'å‹•è©',
        'japanese_synonyms': f"{ko_word}_æ—¥æœ¬èªé¡,é–¢é€£èª",
        'japanese_antonyms': f"é{ko_word}_æ—¥æœ¬èª,åå¯¾èª",
        'japanese_word_family': f"{ko_word}_æ—¥æœ¬èªæ—,{ko_word}_æ—¥æœ¬èªç³»åˆ—",
        'japanese_compound_words': f"{ko_word}_æ—¥æœ¬èªè¡¨ç¾,{ko_word}_æ—¥æœ¬èªç”¨èª",
        'japanese_collocations': f"{ko_word}_æ—¥æœ¬èªã‚’è¨€ã†,{ko_word}_æ—¥æœ¬èªã§æŒ¨æ‹¶ã™ã‚‹",
        'spanish_word': f"{ko_word}_espaÃ±ol",
        'spanish_pronunciation': f"{ko_word}_espaÃ±ol_pronunciaciÃ³n",
        'spanish_definition': f"{ko_word} definiciÃ³n espaÃ±ol",
        'spanish_pos': 'sustantivo' if meta['pos'] != 'verb' else 'verbo',
        'spanish_synonyms': f"{ko_word}_espaÃ±ol tipo,expresiÃ³n relacionada",
        'spanish_antonyms': f"no {ko_word}_espaÃ±ol,opuesto",
        'spanish_word_family': f"familia {ko_word}_espaÃ±ol,grupo {ko_word}_espaÃ±ol",
        'spanish_compound_words': f"saludo de {ko_word}_espaÃ±ol,frase de {ko_word}_espaÃ±ol",
        'spanish_collocations': f"decir {ko_word}_espaÃ±ol,ofrecer {ko_word}_espaÃ±ol",
        'korean_example': meta['ko_examples']['concepts'],
        'english_example': meta['en_examples']['concepts'],
        'chinese_example': f"æˆ‘ä»¬åœ¨å®¶é‡Œè¯´{ko_word}_ä¸­æ–‡ã€‚",
        'japanese_example': f"å®¶ã§{ko_word}_æ—¥æœ¬èªã¨æŒ¨æ‹¶ã—ã¾ã—ãŸã€‚",
        'spanish_example': f"En casa dijimos {ko_word}_espaÃ±ol."
    }


def build_examples_row(meta, ko_word: str):
    # Header: 16 fields
    return {
        'concept_id': meta['concept_id'],
        'domain': meta['domain'],
        'category': meta['category'],
        'difficulty': meta['difficulty'],
        'situation': meta['situation'],
        'purpose': meta['purpose'],
        'korean': meta['ko_examples']['examples'],
        'english': meta['en_examples']['examples'],
        'japanese': f"ä»Šæœã€å®¶ã§{ko_word}_æ—¥æœ¬èªã¨å£°ã‚’ã‹ã‘ã¾ã—ãŸã€‚",
        'chinese': f"ä»Šå¤©æ—©ä¸Šåœ¨å®¶å¯¹å®¶äººè¯´äº†{ko_word}_ä¸­æ–‡ã€‚",
        'spanish': f"Esta maÃ±ana en casa dije {ko_word}_espaÃ±ol.",
        'korean_word': ko_word,
        'english_word': meta['english_word_readable'],
        'japanese_word': f"{ko_word}_æ—¥æœ¬èª",
        'chinese_word': f"{ko_word}_ä¸­æ–‡",
        'spanish_word': f"{ko_word}_espaÃ±ol",
    }


def build_grammar_row(meta, ko_word: str):
    pos = meta['pos']
    en_word = meta['english_word_readable']
    en_token = meta['english_word_token']

    if pos == 'interjection':
        ko_title = f"'{ko_word}' ì¸ì‚¬"
        ko_structure = "ê°íƒ„ì‚¬ + ì¸ì‚¬"
        ko_desc = f"ì²˜ìŒ ì¸ì‚¬í•  ë•Œ '{ko_word}'ë¥¼ ì‚¬ìš©í•˜ëŠ” êµ¬ì¡°"
        en_title = f"Greeting: {token_to_phrase(en_token)}"
        en_structure = "Interjection + greeting"
        en_desc = f"Using {token_to_phrase(en_token)} as a polite greeting"
    elif pos == 'verb':
        ko_title = f"{ko_word} ì‚¬ìš©ë²•"
        ko_structure = f"ì£¼ì–´ + {ko_word} (+ ëª©ì ì–´)"
        ko_desc = f"ë§Œë‚˜ìë§ˆì {ko_word}í•˜ëŠ” ê¸°ë³¸ ë¬¸ë²•"
        en_title = f"Using {token_to_phrase(en_token)}"
        en_structure = f"Subject + {token_to_phrase(en_token)} (+ object)"
        en_desc = f"Basic pattern to {token_to_phrase(en_token)} in greetings"
    else:  # noun
        ko_title = f"{ko_word} êµ¬ì„±"
        ko_structure = f"í˜•ìš©ì‚¬ + {ko_word}"
        ko_desc = f"ì¸ì‚¬ ìƒí™©ì—ì„œ {ko_word}ë¥¼ ë°°ì¹˜í•˜ëŠ” ë°©ë²•"
        en_title = f"The {token_to_phrase(en_token)}"
        en_structure = f"Adjective + {token_to_phrase(en_token)}"
        en_desc = f"How to place the {token_to_phrase(en_token)} in greetings"

    return {
        'concept_id': meta['concept_id'],
        'domain': meta['domain'],
        'category': meta['category'],
        'difficulty': meta['difficulty'],
        'situation': meta['situation'],
        'purpose': meta['purpose'],
        'korean_title': ko_title,
        'korean_structure': ko_structure,
        'korean_description': ko_desc,
        'korean_example': meta['ko_examples']['grammar'],
        'english_title': en_title,
        'english_structure': en_structure,
        'english_description': en_desc,
        'english_example': meta['en_examples']['grammar'],
        'japanese_title': f"{ko_word}_æ—¥æœ¬èªã®ä½¿ã„æ–¹",
        'japanese_structure': f"æŒ¨æ‹¶ + {ko_word}_æ—¥æœ¬èª",
        'japanese_description': f"æŒ¨æ‹¶ã§{ko_word}_æ—¥æœ¬èªã‚’ä½¿ã†æ–¹æ³•",
        'japanese_example': f"æœ€åˆã«{ko_word}_æ—¥æœ¬èªã¨è¨€ã„ã¾ã™ã€‚",
        'chinese_title': f"{ko_word}_ä¸­æ–‡çš„ç”¨æ³•",
        'chinese_structure': f"é—®å€™ + {ko_word}_ä¸­æ–‡",
        'chinese_description': f"åœ¨é—®å€™æ—¶ä½¿ç”¨{ko_word}_ä¸­æ–‡çš„æ–¹æ³•",
        'chinese_example': f"é¦–å…ˆè¯´{ko_word}_ä¸­æ–‡ã€‚",
        'spanish_title': f"Uso de {ko_word}_espaÃ±ol",
        'spanish_structure': f"Saludo + {ko_word}_espaÃ±ol",
        'spanish_description': f"CÃ³mo usar {ko_word}_espaÃ±ol en los saludos",
        'spanish_example': f"Primero digo {ko_word}_espaÃ±ol.",
        'korean_word': ko_word,
        'english_word': en_word,
        'japanese_word': f"{ko_word}_æ—¥æœ¬èª",
        'chinese_word': f"{ko_word}_ä¸­æ–‡",
        'spanish_word': f"{ko_word}_espaÃ±ol",
    }


def main():
    ensure_dir(RESULT_DIR)

    # Configuration from the batch prompt
    DOMAIN = "daily"
    CATEGORY = "routine"
    DIFFICULTY = "basic"
    PURPOSE = "greeting"
    SITUATION = "casual,home"  # will be quoted automatically by csv when needed

    # POS distribution: verb 40% (20), noun 30% (15), interjection 30% (15)
    interjections = [
        ("hello", "ì•ˆë…•í•˜ì„¸ìš”", "greeting"),
        ("hi", "ì•ˆë…•", "greeting"),
        ("hey_there", "ì•ˆë…• ê±°ê¸°", "casual_call"),
        ("good_morning", "ì¢‹ì€ ì•„ì¹¨ì´ì—ìš”", "morning_greeting"),
        ("good_afternoon", "ì¢‹ì€ ì˜¤í›„ì˜ˆìš”", "afternoon_greeting"),
        ("good_evening", "ì¢‹ì€ ì €ë…ì´ì—ìš”", "evening_greeting"),
        ("good_night", "ì¢‹ì€ ë°¤ ë˜ì„¸ìš”", "night_wish"),
        ("welcome", "í™˜ì˜í•©ë‹ˆë‹¤", "welcome"),
        ("long_time_no_see", "ì˜¤ëœë§Œì´ì—ìš”", "reunion_greeting"),
        ("nice_to_meet_you", "ë§Œë‚˜ì„œ ë°˜ê°€ì›Œìš”", "first_meeting"),
        ("pleasure_to_meet_you", "ë§Œë‚˜ì„œ ê¸°ì©ë‹ˆë‹¤", "polite_meeting"),
        ("hi_everyone", "ëª¨ë‘ ì•ˆë…•í•˜ì„¸ìš”", "group_greeting"),
        ("greetings", "ì¸ì‚¬ë“œë¦½ë‹ˆë‹¤", "formal_greeting"),
        ("good_to_see_you", "ëµ™ê²Œ ë˜ì–´ ë°˜ê°‘ìŠµë‹ˆë‹¤", "reunion_polite"),
        ("welcome_home", "ì§‘ì— ì˜¤ì‹  ê±¸ í™˜ì˜í•´ìš”", "home_welcome"),
    ]

    nouns = [
        ("greeting", "ì¸ì‚¬", "greeting_concept"),
        ("handshake", "ì•…ìˆ˜", "gesture"),
        ("bow", "ì ˆ", "gesture"),
        ("smile", "ë¯¸ì†Œ", "expression"),
        ("introduction", "ì†Œê°œ", "first_meeting"),
        ("courtesy", "ì˜ˆì˜", "manner"),
        ("respect", "ì¡´ì¤‘", "manner"),
        ("salutation", "ê²½ë¡€", "formal_salute"),
        ("politeness", "ê³µì†í•¨", "manner"),
        ("hospitality", "í™˜ëŒ€", "welcome"),
        ("reunion", "ì¬íšŒ", "meeting_again"),
        ("small_talk", "ì¡ë‹´", "icebreaker"),
        ("first_meeting", "ì²«ë§Œë‚¨", "start"),
        ("farewell", "ì‘ë³„", "goodbye"),
        ("icebreaker", "ì•„ì´ìŠ¤ë¸Œë ˆì´ì»¤", "breaker"),
    ]

    verbs = [
        ("greet", "ì¸ì‚¬í•˜ë‹¤", "action"),
        ("meet", "ë§Œë‚˜ë‹¤", "meet"),
        ("introduce", "ì†Œê°œí•˜ë‹¤", "introduce"),
        ("welcome_back", "ë‹¤ì‹œ í™˜ì˜í•˜ë‹¤", "welcome"),
        ("wave", "ì†ì„ í”ë“¤ë‹¤", "gesture"),
        ("smile_verb", "ë¯¸ì†Œì§“ë‹¤", "expression"),
        ("nod", "ê³ ê°œë¥¼ ë„ë•ì´ë‹¤", "gesture"),
        ("shake_hands", "ì•…ìˆ˜í•˜ë‹¤", "gesture"),
        ("bow_verb", "ì ˆí•˜ë‹¤", "gesture"),
        ("say_hello", "'ì•ˆë…•í•˜ì„¸ìš”'ë¼ê³  ë§í•˜ë‹¤", "utterance"),
        ("ask_how_are_you", "ì•ˆë¶€ë¥¼ ë¬»ë‹¤", "utterance"),
        ("respond_im_fine", "ê´œì°®ë‹¤ê³  ë‹µí•˜ë‹¤", "reply"),
        ("start_conversation", "ëŒ€í™”ë¥¼ ì‹œì‘í•˜ë‹¤", "start"),
        ("make_small_talk", "ê°€ë²¼ìš´ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ë‹¤", "icebreaker"),
        ("check_in_on_you", "ì•ˆë¶€ë¥¼ í™•ì¸í•˜ë‹¤", "care"),
        ("wish_good_day", "ì¢‹ì€ í•˜ë£¨ë¥¼ ë¹Œë‹¤", "wish"),
        ("wish_good_night", "ì¢‹ì€ ë°¤ì„ ë¹Œë‹¤", "wish"),
        ("compliment", "ì¹­ì°¬í•˜ë‹¤", "praise"),
        ("thank_for_coming", "ì™€ì¤˜ì„œ ê³ ë§™ë‹¤ê³  ë§í•˜ë‹¤", "thanks"),
        ("welcome_verb", "í™˜ì˜í•˜ë‹¤", "welcome"),
    ]

    assert len(interjections) == 15 and len(nouns) == 15 and len(verbs) == 20, "POS counts must be 15/15/20"

    items = [("interjection",) + t for t in interjections]
    items += [("noun",) + t for t in nouns]
    items += [("verb",) + t for t in verbs]

    # Build data rows
    concepts_rows = []
    examples_rows = []
    grammar_rows = []

    # Header definitions (exact order)
    concepts_header = [
        'concept_id','domain','category','difficulty','emoji','color','situation','purpose',
        'korean_word','korean_pronunciation','korean_definition','korean_pos','korean_synonyms','korean_antonyms','korean_word_family','korean_compound_words','korean_collocations',
        'english_word','english_pronunciation','english_definition','english_pos','english_synonyms','english_antonyms','english_word_family','english_compound_words','english_collocations',
        'chinese_word','chinese_pronunciation','chinese_definition','chinese_pos','chinese_synonyms','chinese_antonyms','chinese_word_family','chinese_compound_words','chinese_collocations',
        'japanese_word','japanese_pronunciation','japanese_definition','japanese_pos','japanese_synonyms','japanese_antonyms','japanese_word_family','japanese_compound_words','japanese_collocations',
        'spanish_word','spanish_pronunciation','spanish_definition','spanish_pos','spanish_synonyms','spanish_antonyms','spanish_word_family','spanish_compound_words','spanish_collocations',
        'korean_example','english_example','chinese_example','japanese_example','spanish_example'
    ]

    examples_header = [
        'concept_id','domain','category','difficulty','situation','purpose',
        'korean','english','japanese','chinese','spanish',
        'korean_word','english_word','japanese_word','chinese_word','spanish_word'
    ]

    grammar_header = [
        'concept_id','domain','category','difficulty','situation','purpose',
        'korean_title','korean_structure','korean_description','korean_example',
        'english_title','english_structure','english_description','english_example',
        'japanese_title','japanese_structure','japanese_description','japanese_example',
        'chinese_title','chinese_structure','chinese_description','chinese_example',
        'spanish_title','spanish_structure','spanish_description','spanish_example',
        'korean_word','english_word','japanese_word','chinese_word','spanish_word'
    ]

    # Emojis/colors for variety
    emojis = ["â°", "ğŸ™‚", "ğŸ‘‹", "ğŸŒ…", "ğŸ "]
    colors = ["#4CAF50", "#2196F3", "#FF9800", "#9C27B0", "#009688"]

    for idx, item in enumerate(items):
        pos, en_token, ko_word, meaning = item

        # Build concept_id using english token and meaning
        safe_token = re.sub(r"[^a-z0-9_]+", "_", en_token.lower())
        safe_meaning = re.sub(r"[^a-z0-9_]+", "_", meaning.lower())
        concept_id = f"{DOMAIN}_{safe_token}_{safe_meaning}"

        english_word_readable = token_to_phrase(en_token)

        meta = {
            'concept_id': concept_id,
            'domain': DOMAIN,
            'category': CATEGORY,
            'difficulty': DIFFICULTY,
            'emoji': emojis[idx % len(emojis)],
            'color': colors[idx % len(colors)],
            'situation': SITUATION,
            'purpose': PURPOSE,
            'pos': pos,
            'korean_pos': 'ê°íƒ„ì‚¬' if pos == 'interjection' else ('ë™ì‚¬' if pos == 'verb' else 'ëª…ì‚¬'),
            'english_pos': 'interjection' if pos == 'interjection' else ('verb' if pos == 'verb' else 'noun'),
            'english_word_token': safe_token,
            'english_word_readable': english_word_readable,
            'ko_examples': {
                'concepts': ko_sentence('concepts', ko_word, pos),
                'examples': ko_sentence('examples', ko_word, pos),
                'grammar': ko_sentence('grammar', ko_word, pos),
            },
            'en_examples': {
                'concepts': en_sentence('concepts', en_token, pos),
                'examples': en_sentence('examples', en_token, pos),
                'grammar': en_sentence('grammar', en_token, pos),
            }
        }

        concepts_rows.append(build_concepts_row(meta, ko_word))
        examples_rows.append(build_examples_row(meta, ko_word))
        grammar_rows.append(build_grammar_row(meta, ko_word))

    # Write CSVs to result/, UTF-8 without BOM
    result_files = [
        (RESULT_DIR / 'batch_1-1_concepts_template_add.csv', concepts_header, concepts_rows),
        (RESULT_DIR / 'batch_1-1_examples_template_add.csv', examples_header, examples_rows),
        (RESULT_DIR / 'batch_1-1_grammar_template_add.csv', grammar_header, grammar_rows),
    ]

    for path, header, rows in result_files:
        with open(path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=header)
            writer.writeheader()
            writer.writerows(rows)
        print(f"Wrote {path.name}: {len(rows)} rows, {len(header)} fields (UTF-8 no BOM)")


if __name__ == '__main__':
    main()
