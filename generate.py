#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Generate Templates - ìƒˆë¡œìš´ ëœë¤ í…œí”Œë¦¿ ìƒì„±
í˜„ì¬ 4ë‹¨ê³„ ì›Œí¬í”Œë¡œìš°: generate.py â†’ validate.py â†’ accumulator.py â†’ backup.py/restore.py
"""

import random
import csv
from pathlib import Path
import datetime
import json

def generate_differentiated_examples(korean_word, english_word, collection_type):
    """ì»¬ë ‰ì…˜ë³„ë¡œ ì°¨ë³„í™”ëœ ì˜ˆë¬¸ ìƒì„±"""
    
    # ë‹¨ì–´ë³„ ì˜ˆë¬¸ íŒ¨í„´ ë§¤í•‘
    word_patterns = {
        "ì‚¬ê³¼": {
            "concepts": ("ì‚¬ê³¼ëŠ” ë§›ìˆëŠ” ê³¼ì¼ì…ë‹ˆë‹¤.", "Apple is a delicious fruit."),
            "examples": ("ì˜¤ëŠ˜ ì ì‹¬ì— ì‚¬ê³¼ë¥¼ ë¨¹ì—ˆìŠµë‹ˆë‹¤.", "I ate an apple for lunch today."),
            "grammar": ("ë‚˜ëŠ” ë¹¨ê°„ ì‚¬ê³¼ë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤.", "I prefer red apples.")
        },
        "ì§‘": {
            "concepts": ("ì§‘ì€ ì‚¬ëŒì´ ì‚¬ëŠ” ê³³ì…ë‹ˆë‹¤.", "A house is where people live."),
            "examples": ("ìƒˆë¡œìš´ ì§‘ìœ¼ë¡œ ì´ì‚¬í–ˆìŠµë‹ˆë‹¤.", "We moved to a new house."),
            "grammar": ("ê·¸ì˜ ì§‘ì€ í•™êµ ê·¼ì²˜ì— ìˆìŠµë‹ˆë‹¤.", "His house is near the school.")
        },
        "í•™êµ": {
            "concepts": ("í•™êµëŠ” ë°°ì›€ì˜ ì¥ì†Œì…ë‹ˆë‹¤.", "School is a place of learning."),
            "examples": ("ë§¤ì¼ ì•„ì¹¨ í•™êµì— ê°‘ë‹ˆë‹¤.", "I go to school every morning."),
            "grammar": ("ìš°ë¦¬ í•™êµëŠ” ë§¤ìš° í½ë‹ˆë‹¤.", "Our school is very large.")
        },
        "ì¹œêµ¬": {
            "concepts": ("ì¹œêµ¬ëŠ” ì†Œì¤‘í•œ ì¡´ì¬ì…ë‹ˆë‹¤.", "A friend is a precious person."),
            "examples": ("ì¹œêµ¬ì™€ í•¨ê»˜ ì˜í™”ë¥¼ ë´¤ìŠµë‹ˆë‹¤.", "I watched a movie with my friend."),
            "grammar": ("ì¢‹ì€ ì¹œêµ¬ë¥¼ ë§Œë‚˜ê¸°ëŠ” ì–´ë µìŠµë‹ˆë‹¤.", "It's hard to meet good friends.")
        },
        "ìŒì‹": {
            "concepts": ("ìŒì‹ì€ ìƒì¡´ì— í•„ìš”í•©ë‹ˆë‹¤.", "Food is necessary for survival."),
            "examples": ("í•œêµ­ ìŒì‹ì„ ì¢‹ì•„í•©ë‹ˆë‹¤.", "I like Korean food."),
            "grammar": ("ë§›ìˆëŠ” ìŒì‹ì„ ë§Œë“¤ì–´ ë³´ì„¸ìš”.", "Try making delicious food.")
        },
        "ìë™ì°¨": {
            "concepts": ("ìë™ì°¨ëŠ” í¸ë¦¬í•œ êµí†µìˆ˜ë‹¨ì…ë‹ˆë‹¤.", "A car is a convenient means of transportation."),
            "examples": ("ìƒˆ ìë™ì°¨ë¥¼ êµ¬ë§¤í–ˆìŠµë‹ˆë‹¤.", "I bought a new car."),
            "grammar": ("ê·¸ëŠ” ë¹¨ê°„ ìë™ì°¨ë¥¼ ìš´ì „í•©ë‹ˆë‹¤.", "He drives a red car.")
        },
        "ì±…": {
            "concepts": ("ì±…ì€ ì§€ì‹ì˜ ë³´ê³ ì…ë‹ˆë‹¤.", "Books are treasures of knowledge."),
            "examples": ("ë„ì„œê´€ì—ì„œ ì±…ì„ ë¹Œë ¸ìŠµë‹ˆë‹¤.", "I borrowed a book from the library."),
            "grammar": ("ì´ ì±…ì„ ì½ì–´ ë³´ì„¸ìš”.", "Please read this book.")
        },
        "ë‚˜ë¬´": {
            "concepts": ("ë‚˜ë¬´ëŠ” ì‚°ì†Œë¥¼ ë§Œë“­ë‹ˆë‹¤.", "Trees produce oxygen."),
            "examples": ("ê³µì›ì— í° ë‚˜ë¬´ê°€ ìˆìŠµë‹ˆë‹¤.", "There is a big tree in the park."),
            "grammar": ("ì € ë‚˜ë¬´ëŠ” 100ë…„ ë˜ì—ˆìŠµë‹ˆë‹¤.", "That tree is 100 years old.")
        }
    }
    
    # ê¸°ë³¸ íŒ¨í„´ (ë‹¨ì–´ë³„ íŒ¨í„´ì´ ì—†ëŠ” ê²½ìš°)
    default_patterns = {
        "concepts": (f"{korean_word}ëŠ” ì¤‘ìš”í•œ ê°œë…ì…ë‹ˆë‹¤.", f"{english_word.capitalize()} is an important concept."),
        "examples": (f"ì˜¤ëŠ˜ {korean_word}ì— ëŒ€í•´ ë°°ì› ìŠµë‹ˆë‹¤.", f"I learned about {english_word} today."),
        "grammar": (f"ì´ {korean_word}ë¥¼ ì‚¬ìš©í•´ ë³´ì„¸ìš”.", f"Please use this {english_word}.")
    }
    
    # í•´ë‹¹ ë‹¨ì–´ì˜ íŒ¨í„´ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ íŒ¨í„´ ì‚¬ìš©
    if korean_word in word_patterns:
        patterns = word_patterns[korean_word]
    else:
        patterns = default_patterns
    
    return patterns[collection_type]

def generate_random_templates():
    """ëœë¤ í…œí”Œë¦¿ ë°ì´í„° ìƒì„±"""
    print("ğŸ² ëœë¤ í…œí”Œë¦¿ ìƒì„± ì‹œì‘...")
    
    # ê¸°ë³¸ ì„¤ì •
    base_dir = Path(__file__).parent
    data_dir = base_dir / "data"
    
    # ê¸°ì¡´ concept_id ìˆ˜ì§‘ (ì¤‘ë³µ ë°©ì§€ìš©)
    existing_concept_ids = set()
    existing_word_meanings = set()  # ë‹¨ì–´+ì˜ë¯¸ ì¡°í•© ì¶”ì 
    list_files = ["concepts_template_list.csv", "examples_template_list.csv", "grammar_template_list.csv"]
    
    for file_name in list_files:
        file_path = data_dir / file_name
        if file_path.exists():
            try:
                with open(file_path, "r", encoding="utf-8-sig") as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        concept_id = row.get('concept_id')
                        if concept_id:
                            existing_concept_ids.add(concept_id)
                            
                            # concepts íŒŒì¼ì—ì„œ ë‹¨ì–´+ì˜ë¯¸ ì¡°í•©ë„ ìˆ˜ì§‘
                            if "concepts_template" in file_name:
                                english_word = row.get('english_word', '')
                                korean_word = row.get('korean_word', '')
                                if english_word and korean_word:
                                    parts = concept_id.split('_')
                                    meaning = parts[-1] if len(parts) >= 3 else 'unknown'
                                    en_combination = f"{english_word}_{meaning}"
                                    ko_combination = f"{korean_word}_{meaning}"
                                    existing_word_meanings.add(en_combination)
                                    existing_word_meanings.add(ko_combination)
            except Exception as e:
                print(f"âš ï¸ {file_name} ì½ê¸° ì‹¤íŒ¨: {e}")
    
    print(f"ğŸ” ê¸°ì¡´ concept_id {len(existing_concept_ids)}ê°œ, ë‹¨ì–´+ì˜ë¯¸ ì¡°í•© {len(existing_word_meanings)}ê°œ ë°œê²¬")
    
    # ë„ë©”ì¸ê³¼ ì¹´í…Œê³ ë¦¬ ë§¤í•‘
    domains = {
        "daily": ["routine", "family", "communication"],
        "food": ["fruit", "vegetable", "drink"],
        "travel": ["transportation", "accommodation", "sightseeing"],
        "health": ["medicine", "body", "fitness"],
        "nature": ["animal", "plant", "weather"],
        "shopping": ["store", "product", "payment"]
    }
    
    # ëœë¤ ë°ì´í„° ìƒì„±
    concepts_data = []
    examples_data = []
    grammar_data = []
    
    # 5ê°œ ëœë¤ concept ìƒì„±
    generated_concept_ids = set()  # ì´ë²ˆ ìƒì„±ì—ì„œ concept_id ì¤‘ë³µ ë°©ì§€
    generated_word_meanings = set()  # ì´ë²ˆ ìƒì„±ì—ì„œ ë‹¨ì–´+ì˜ë¯¸ ì¤‘ë³µ ë°©ì§€
    
    for i in range(5):
        max_attempts = 20  # ì¤‘ë³µ ì‹œ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì¦ê°€
        attempt = 0
        
        while attempt < max_attempts:
            domain = random.choice(list(domains.keys()))
            category = random.choice(domains[domain])
            
            # ë‹¨ì–´ì™€ ì˜ë¯¸ ë§¤í•‘ ì •ì˜ (ì˜ì–´ ë‹¨ì–´ ê¸°ì¤€)
            word_meaning_map = {
                "apple": "fruit",
                "book": "knowledge", 
                "car": "transport",
                "house": "shelter",
                "tree": "nature"
            }
            
            korean_word_map = {
                "apple": "ì‚¬ê³¼",
                "book": "ì±…",
                "car": "ìë™ì°¨", 
                "house": "ì§‘",
                "tree": "ë‚˜ë¬´"
            }
            
            english_word = random.choice(["apple", "book", "car", "house", "tree"])
            korean_word = korean_word_map[english_word]
            meaning = word_meaning_map[english_word]
            
            # ì˜¬ë°”ë¥¸ í˜•ì‹: {domain}_{word}_{meaning}
            concept_id = f"{domain}_{english_word}_{meaning}"
            
            # ë‹¨ì–´+ì˜ë¯¸ ì¡°í•©
            en_combination = f"{english_word}_{meaning}"
            ko_combination = f"{korean_word}_{meaning}"
            
            # ì¤‘ë³µ ê²€ì‚¬: concept_id + ë‹¨ì–´+ì˜ë¯¸ ì¡°í•©
            if (concept_id not in existing_concept_ids and 
                concept_id not in generated_concept_ids and
                en_combination not in existing_word_meanings and
                ko_combination not in existing_word_meanings and
                en_combination not in generated_word_meanings and
                ko_combination not in generated_word_meanings):
                
                generated_concept_ids.add(concept_id)
                generated_word_meanings.add(en_combination)
                generated_word_meanings.add(ko_combination)
                break
            else:
                if concept_id in existing_concept_ids or concept_id in generated_concept_ids:
                    print(f"âš ï¸ concept_id ì¤‘ë³µ: {concept_id} (ì¬ì‹œë„ {attempt + 1}/{max_attempts})")
                else:
                    print(f"âš ï¸ ë‹¨ì–´+ì˜ë¯¸ ì¤‘ë³µ: {en_combination} (ì¬ì‹œë„ {attempt + 1}/{max_attempts})")
                attempt += 1
        
        if attempt >= max_attempts:
            print(f"âŒ concept_id ìƒì„± ì‹¤íŒ¨: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ (ì‹œë„í•œ ì¡°í•©: {domain}_{english_word}_{meaning})")
            continue
        
        # ì°¨ë³„í™”ëœ ì˜ˆë¬¸ ìƒì„±
        concept_examples = generate_differentiated_examples(korean_word, english_word, "concepts")
        example_examples = generate_differentiated_examples(korean_word, english_word, "examples")
        grammar_examples = generate_differentiated_examples(korean_word, english_word, "grammar")
        
        # Concepts ë°ì´í„°
        concept = {
            "concept_id": concept_id,
            "domain": domain,
            "category": category,
            "difficulty": random.choice(["basic", "intermediate", "advanced"]),
            "emoji": random.choice(["ğŸ", "ğŸ“š", "ğŸš—", "ğŸ ", "ğŸŒ³"]),
            "color": random.choice(["#FF5722", "#4CAF50", "#2196F3", "#FF9800"]),
            "situation": "formal",
            "purpose": random.choice(["description", "question", "greeting"]),
            "korean_word": korean_word,
            "english_word": english_word,
            # ì˜ˆë¬¸ ì°¨ë³„í™”: Concepts = ê¸°ë³¸ ì˜ë¯¸ í‘œí˜„
            "korean_example": concept_examples[0],
            "english_example": concept_examples[1]
        }
        concepts_data.append(concept)
        
        # Examples ë°ì´í„°
        example = {
            "concept_id": concept_id,
            "domain": domain,
            "category": category,
            "difficulty": concept["difficulty"],
            "situation": "formal",
            "purpose": concept["purpose"],
            # ì˜ˆë¬¸ ì°¨ë³„í™”: Examples = ì‹¤ì œ ìƒí™© ì‚¬ìš©
            "korean": example_examples[0],
            "english": example_examples[1],
            "korean_word": concept["korean_word"],
            "english_word": concept["english_word"]
        }
        examples_data.append(example)
        
        # Grammar ë°ì´í„°
        grammar = {
            "concept_id": concept_id,
            "domain": domain,
            "category": category,
            "difficulty": concept["difficulty"],
            "situation": "formal",
            "purpose": concept["purpose"],
            "korean_title": "ë¬¸ë²• íŒ¨í„´",
            "korean_structure": "N + V",
            "korean_description": "ê¸°ë³¸ ë¬¸ë²• ì„¤ëª…",
            # ì˜ˆë¬¸ ì°¨ë³„í™”: Grammar = ë¬¸ë²• íŒ¨í„´ ì„¤ëª…
            "korean_example": grammar_examples[0],
            "english_title": "Grammar Pattern",
            "english_structure": "S + V + O",
            "english_description": "Basic grammar explanation",
            "english_example": grammar_examples[1],
            "korean_word": concept["korean_word"],
            "english_word": concept["english_word"]
        }
        grammar_data.append(grammar)
    
    # CSV íŒŒì¼ ì €ì¥
    save_csv_templates(data_dir, concepts_data, examples_data, grammar_data)
    print(f"âœ… ëœë¤ í…œí”Œë¦¿ ìƒì„± ì™„ë£Œ: {len(concepts_data)}ê°œ concept")

def save_csv_templates(data_dir, concepts_data, examples_data, grammar_data):
    """CSV íŒŒì¼ë¡œ í…œí”Œë¦¿ ì €ì¥ (58ê°œ í•„ë“œ ì™„ì „ êµ¬ì¡°)"""
    
    # ì •í™•í•œ 58ê°œ í•„ë“œ ìˆœì„œ (í†µí•©_ë°ì´í„°_ê°€ì´ë“œ.md ê¸°ì¤€)
    concepts_header = [
        'concept_id','domain','category','difficulty','emoji','color','situation','purpose',
        'korean_word','korean_pronunciation','korean_definition','korean_pos','korean_synonyms','korean_antonyms','korean_word_family','korean_compound_words','korean_collocations',
        'english_word','english_pronunciation','english_definition','english_pos','english_synonyms','english_antonyms','english_word_family','english_compound_words','english_collocations',
        'chinese_word','chinese_pronunciation','chinese_definition','chinese_pos','chinese_synonyms','chinese_antonyms','chinese_word_family','chinese_compound_words','chinese_collocations',
        'japanese_word','japanese_pronunciation','japanese_definition','japanese_pos','japanese_synonyms','japanese_antonyms','japanese_word_family','japanese_compound_words','japanese_collocations',
        'spanish_word','spanish_pronunciation','spanish_definition','spanish_pos','spanish_synonyms','spanish_antonyms','spanish_word_family','spanish_compound_words','spanish_collocations',
        'korean_example','english_example','chinese_example','japanese_example','spanish_example'
    ]
    
    # Examples CSV í—¤ë” (16ê°œ í•„ë“œ)
    examples_header = [
        "concept_id", "domain", "category", "difficulty", "situation", "purpose",
        "korean", "english", "japanese", "chinese", "spanish",
        "korean_word", "english_word", "japanese_word", "chinese_word", "spanish_word"
    ]
    
    # Grammar CSV í—¤ë” (31ê°œ í•„ë“œ)
    grammar_header = [
        "concept_id", "domain", "category", "difficulty", "situation", "purpose",
        "korean_title", "korean_structure", "korean_description", "korean_example",
        "english_title", "english_structure", "english_description", "english_example",
        "japanese_title", "japanese_structure", "japanese_description", "japanese_example",
        "chinese_title", "chinese_structure", "chinese_description", "chinese_example",
        "spanish_title", "spanish_structure", "spanish_description", "spanish_example",
        "korean_word", "english_word", "japanese_word", "chinese_word", "spanish_word"
    ]
    
    # Concepts ë°ì´í„°ë¥¼ 58ê°œ í•„ë“œë¡œ í™•ì¥
    expanded_concepts_data = []
    for concept in concepts_data:
        expanded_concept = {
            # ê¸°ë³¸ ì •ë³´ (8ê°œ)
            'concept_id': concept['concept_id'],
            'domain': concept['domain'],
            'category': concept['category'],
            'difficulty': concept['difficulty'],
            'emoji': concept.get('emoji', 'ğŸ“š'),
            'color': concept.get('color', '#4CAF50'),
            'situation': concept['situation'],
            'purpose': concept['purpose'],
            
            # í•œêµ­ì–´ (9ê°œ í•„ë“œ)
            'korean_word': concept['korean_word'],
            'korean_pronunciation': f"{concept['korean_word']}-pronunciation",
            'korean_definition': f"{concept['korean_word']} ì •ì˜",
            'korean_pos': 'ëª…ì‚¬',
            'korean_synonyms': f"{concept['korean_word']}ë¥˜,ê´€ë ¨ì–´",
            'korean_antonyms': f"ë¹„{concept['korean_word']},ë°˜ëŒ€ë§",
            'korean_word_family': f"{concept['korean_word']}ì¡±,{concept['korean_word']}ê³„ì—´",
            'korean_compound_words': f"{concept['korean_word']}ë‚˜ë¬´,{concept['korean_word']}ì¦™",
            'korean_collocations': f"{concept['korean_word']}ì„ ë¨¹ë‹¤,{concept['korean_word']}ì„ ì‚¬ë‹¤",
            
            # ì˜ì–´ (9ê°œ í•„ë“œ)
            'english_word': concept['english_word'],
            'english_pronunciation': f"/{concept['english_word']}/",
            'english_definition': f"{concept['english_word']} definition",
            'english_pos': 'noun',
            'english_synonyms': f"{concept['english_word']} type,related item",
            'english_antonyms': f"non-{concept['english_word']},opposite",
            'english_word_family': f"{concept['english_word']} family,{concept['english_word']} group",
            'english_compound_words': f"{concept['english_word']} tree,{concept['english_word']} juice",
            'english_collocations': f"eat {concept['english_word']},buy {concept['english_word']}",
            
            # ì¤‘êµ­ì–´ (9ê°œ í•„ë“œ)
            'chinese_word': f"{concept['korean_word']}_ä¸­æ–‡",
            'chinese_pronunciation': f"{concept['korean_word']}_pinyin",
            'chinese_definition': f"{concept['korean_word']} ä¸­æ–‡å®šä¹‰",
            'chinese_pos': 'åè¯',
            'chinese_synonyms': f"{concept['korean_word']}_ä¸­æ–‡ç±»,ç›¸å…³è¯",
            'chinese_antonyms': f"é{concept['korean_word']}_ä¸­æ–‡,åä¹‰è¯",
            'chinese_word_family': f"{concept['korean_word']}_ä¸­æ–‡æ—,{concept['korean_word']}_ä¸­æ–‡ç³»åˆ—",
            'chinese_compound_words': f"{concept['korean_word']}_ä¸­æ–‡æ ‘,{concept['korean_word']}_ä¸­æ–‡æ±",
            'chinese_collocations': f"åƒ{concept['korean_word']}_ä¸­æ–‡,ä¹°{concept['korean_word']}_ä¸­æ–‡",
            
            # ì¼ë³¸ì–´ (9ê°œ í•„ë“œ)
            'japanese_word': f"{concept['korean_word']}_æ—¥æœ¬èª",
            'japanese_pronunciation': f"{concept['korean_word']}_hiragana",
            'japanese_definition': f"{concept['korean_word']} æ—¥æœ¬èªå®šç¾©",
            'japanese_pos': 'åè©',
            'japanese_synonyms': f"{concept['korean_word']}_æ—¥æœ¬èªé¡,é–¢é€£èª",
            'japanese_antonyms': f"é{concept['korean_word']}_æ—¥æœ¬èª,åå¯¾èª",
            'japanese_word_family': f"{concept['korean_word']}_æ—¥æœ¬èªæ—,{concept['korean_word']}_æ—¥æœ¬èªç³»åˆ—",
            'japanese_compound_words': f"{concept['korean_word']}_æ—¥æœ¬èªã®æœ¨,{concept['korean_word']}_æ—¥æœ¬èªã‚¸ãƒ¥ãƒ¼ã‚¹",
            'japanese_collocations': f"{concept['korean_word']}_æ—¥æœ¬èªã‚’é£Ÿã¹ã‚‹,{concept['korean_word']}_æ—¥æœ¬èªã‚’è²·ã†",
            
            # ìŠ¤í˜ì¸ì–´ (9ê°œ í•„ë“œ)
            'spanish_word': f"{concept['korean_word']}_espaÃ±ol",
            'spanish_pronunciation': f"{concept['korean_word']}_espaÃ±ol_pronunciation",
            'spanish_definition': f"{concept['korean_word']} definiciÃ³n espaÃ±ol",
            'spanish_pos': 'sustantivo',
            'spanish_synonyms': f"{concept['korean_word']}_espaÃ±ol tipo,artÃ­culo relacionado",
            'spanish_antonyms': f"no {concept['korean_word']}_espaÃ±ol,opuesto",
            'spanish_word_family': f"familia {concept['korean_word']}_espaÃ±ol,grupo {concept['korean_word']}_espaÃ±ol",
            'spanish_compound_words': f"Ã¡rbol de {concept['korean_word']}_espaÃ±ol,jugo de {concept['korean_word']}_espaÃ±ol",
            'spanish_collocations': f"comer {concept['korean_word']}_espaÃ±ol,comprar {concept['korean_word']}_espaÃ±ol",
            
            # ëŒ€í‘œ ì˜ˆë¬¸ (5ê°œ í•„ë“œ)
            'korean_example': concept.get('korean_example', f"{concept['korean_word']}ë¥¼ ì‚¬ìš©í•´ìš”"),
            'english_example': concept.get('english_example', f"I use {concept['english_word']}"),
            'chinese_example': f"æˆ‘ä½¿ç”¨{concept['korean_word']}_ä¸­æ–‡",
            'japanese_example': f"{concept['korean_word']}_æ—¥æœ¬èªã‚’ä½¿ã„ã¾ã™",
            'spanish_example': f"Uso {concept['korean_word']}_espaÃ±ol"
        }
        expanded_concepts_data.append(expanded_concept)
    
    # Examples ë°ì´í„°ë¥¼ 16ê°œ í•„ë“œë¡œ í™•ì¥
    expanded_examples_data = []
    for example in examples_data:
        expanded_example = {
            "concept_id": example["concept_id"],
            "domain": example["domain"],
            "category": example["category"],
            "difficulty": example["difficulty"],
            "situation": example["situation"],
            "purpose": example["purpose"],
            # ì°¨ë³„í™”ëœ ì˜ˆë¬¸ ìœ ì§€ (ë®ì–´ì“°ì§€ ì•ŠìŒ)
            "korean": example["korean"],
            "english": example["english"],
            "japanese": f"{example['korean_word']}_æ—¥æœ¬èªã«ã¤ã„ã¦è©±ã—ã¾ã—ã‚‡ã†",
            "chinese": f"æˆ‘ä»¬æ¥è°ˆè®º{example['korean_word']}_ä¸­æ–‡",
            "spanish": f"Hablemos sobre {example['korean_word']}_espaÃ±ol",
            "korean_word": example["korean_word"],
            "english_word": example["english_word"],
            "japanese_word": f"{example['korean_word']}_æ—¥æœ¬èª",
            "chinese_word": f"{example['korean_word']}_ä¸­æ–‡",
            "spanish_word": f"{example['korean_word']}_espaÃ±ol"
        }
        expanded_examples_data.append(expanded_example)
    
    # Grammar ë°ì´í„°ë¥¼ 31ê°œ í•„ë“œë¡œ í™•ì¥
    expanded_grammar_data = []
    for grammar in grammar_data:
        expanded_grammar = {
            "concept_id": grammar["concept_id"],
            "domain": grammar["domain"],
            "category": grammar["category"],
            "difficulty": grammar["difficulty"],
            "situation": grammar["situation"],
            "purpose": grammar["purpose"],
            
            # í•œêµ­ì–´ íŒ¨í„´ (4ê°œ í•„ë“œ)
            "korean_title": f"{grammar['korean_word']} ì‚¬ìš©ë²•",
            "korean_structure": f"{grammar['korean_word']} + ë¥¼/ì„",
            "korean_description": f"{grammar['korean_word']}ë¥¼ ì‚¬ìš©í•˜ëŠ” ë¬¸ë²• íŒ¨í„´",
            # ì°¨ë³„í™”ëœ ì˜ˆë¬¸ ìœ ì§€ (ë®ì–´ì“°ì§€ ì•ŠìŒ)
            "korean_example": grammar["korean_example"],
            
            # ì˜ì–´ íŒ¨í„´ (4ê°œ í•„ë“œ)
            "english_title": f"Using {grammar['english_word']}",
            "english_structure": f"Subject + verb + {grammar['english_word']}",
            "english_description": f"Grammar pattern for using {grammar['english_word']}",
            # ì°¨ë³„í™”ëœ ì˜ˆë¬¸ ìœ ì§€ (ë®ì–´ì“°ì§€ ì•ŠìŒ)
            "english_example": grammar["english_example"],
            
            # ì¼ë³¸ì–´ íŒ¨í„´ (4ê°œ í•„ë“œ)
            "japanese_title": f"{grammar['korean_word']}_æ—¥æœ¬èªã®ä½¿ã„æ–¹",
            "japanese_structure": f"{grammar['korean_word']}_æ—¥æœ¬èª + ã‚’",
            "japanese_description": f"{grammar['korean_word']}_æ—¥æœ¬èªã‚’ä½¿ã†æ–‡æ³•ãƒ‘ã‚¿ãƒ¼ãƒ³",
            "japanese_example": f"ç§ã¯{grammar['korean_word']}_æ—¥æœ¬èªãŒå¥½ãã§ã™",
            
            # ì¤‘êµ­ì–´ íŒ¨í„´ (4ê°œ í•„ë“œ)
            "chinese_title": f"{grammar['korean_word']}_ä¸­æ–‡çš„ç”¨æ³•",
            "chinese_structure": f"ä¸»è¯­ + åŠ¨è¯ + {grammar['korean_word']}_ä¸­æ–‡",
            "chinese_description": f"ä½¿ç”¨{grammar['korean_word']}_ä¸­æ–‡çš„è¯­æ³•æ¨¡å¼",
            "chinese_example": f"æˆ‘å–œæ¬¢{grammar['korean_word']}_ä¸­æ–‡",
            
            # ìŠ¤í˜ì¸ì–´ íŒ¨í„´ (4ê°œ í•„ë“œ)
            "spanish_title": f"Uso de {grammar['korean_word']}_espaÃ±ol",
            "spanish_structure": f"Sujeto + verbo + {grammar['korean_word']}_espaÃ±ol",
            "spanish_description": f"PatrÃ³n gramatical para usar {grammar['korean_word']}_espaÃ±ol",
            "spanish_example": f"Me gusta {grammar['korean_word']}_espaÃ±ol",
            
            # í•µì‹¬ ë‹¨ì–´ (5ê°œ í•„ë“œ)
            "korean_word": grammar["korean_word"],
            "english_word": grammar["english_word"],
            "japanese_word": f"{grammar['korean_word']}_æ—¥æœ¬èª",
            "chinese_word": f"{grammar['korean_word']}_ä¸­æ–‡",
            "spanish_word": f"{grammar['korean_word']}_espaÃ±ol"
        }
        expanded_grammar_data.append(expanded_grammar)
    
    # CSV íŒŒì¼ ì‘ì„±
    files = [
        ("concepts_template_add.csv", concepts_header, expanded_concepts_data),
        ("examples_template_add.csv", examples_header, expanded_examples_data),
        ("grammar_template_add.csv", grammar_header, expanded_grammar_data)
    ]
    
    for filename, header, data in files:
        filepath = data_dir / filename
        with open(filepath, "w", encoding="utf-8-sig", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=header)
            writer.writeheader()
            writer.writerows(data)
        print(f"ğŸ“„ {filename} ìƒì„± ì™„ë£Œ ({len(header)}ê°œ í•„ë“œ, {len(data)}ê°œ ë ˆì½”ë“œ)")

    print(f"\nğŸ‰ ì™„ì „í•œ í…œí”Œë¦¿ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“Š Concepts: 58ê°œ í•„ë“œ, Examples: 16ê°œ í•„ë“œ, Grammar: 31ê°œ í•„ë“œ")

if __name__ == "__main__":
    generate_random_templates()
    print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. python validate.py     # ì¤‘ë³µ ê²€ì¦")
    print("   2. python accumulator.py  # ë°ì´í„° ëˆ„ì ")
    print("   3. python backup.py       # ë°±ì—… ìƒì„±")
